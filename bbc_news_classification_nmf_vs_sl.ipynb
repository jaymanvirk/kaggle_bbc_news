{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/jaymanvirk/matrix-factorization-nmf-vs-supervised-learning?scriptVersionId=145722092\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"## BBC News Classification: Matrix Factorization vs Supervised Learning","metadata":{}},{"cell_type":"markdown","source":"**Jay Manvirk (Ivan Loginov)**<br/>University of Colorado, Boulder<br/>jay.manvirk@gmail.com","metadata":{}},{"cell_type":"markdown","source":"### Table of Contents\n\n1. [Abstract](#abstract)\n2. [Introduction](#introduction)\n3. [Libraries and raw data](#libraries_data)\n    - 3.1 [Libraries](#libraries)\n    - 3.2 [Raw data](#raw_data)\n4. [Exploratory Data Analysis](#eda)\n    - 4.1 [Short Datasets Summary](#short_summary)\n    - 4.2 [Number of Articles per Category](#articles_per_category)\n    - 4.3 [Word Frequencies](#word_frequencies)\n5. [Data Preprocessing](#data_preprocessing)\n    - 5.1 [Text Cleaning](#text_cleaning)\n    - 5.2 [TF-IDF Vectorization](#tfidf_vectorization)\n6. [Data Modelling](#data_modelling)\n    - 6.1 [Unsupervised Learning (NMF)](#ul_nmf)\n    - 6.2 [Supervised Learning (SL)](#sl)\n7. [Model Results Comparison between NMF and SL](#comparison)\n    - 7.1 [Full Train Dataset](#full_train_dataset)\n    - 7.2 [Samples of the Train Dataset](#samples_train_dataset)\n8. [Submission Results](#submission_results)\n9. [Conclusion](#conclusion)\n10. [References](#references)","metadata":{}},{"cell_type":"markdown","source":"### 1. Abstract <a class=\"anchor\" id=\"abstract\"></a>","metadata":{}},{"cell_type":"markdown","source":"This study presents a fraction of an analysis of a BBC News dataset, encompassing Exploratory Data Analysis (EDA) and preprocessing stages, followed by a performance comparison of Non-Negative Matrix Factorization (NMF) against various supervised learning (SL) algorithms. The dataset comprises articles' texts and their categories: business, sport, tech, politics and entartainment.\n\nThe results of this study showed that SL algorithms such as SVM and Random Forest (RF) scored better than NMF in terms of accuracy, but were completely outperformed by NMF in terms of computational speed.\n\nAdditionally the NMF provided surprising results, when on every sample size, 50%, 20% and 10% of the train dataset, it got test scores on par with the train scores. SVM and RF models while resulting in higher accuracy than NMF across sample sizes, got more prominent overfitting problem with the data size reduction.","metadata":{}},{"cell_type":"markdown","source":"### 2. Introduction <a class=\"anchor\" id=\"introduction\"></a>","metadata":{}},{"cell_type":"markdown","source":"In this notebook we're going to look a bit closer at the model performance comparison between:\n* Unsupervised Learning algorithm, concretely Non-Negative Matrix Factorization\n* Supervised Learning algorithms: Logistic Regression, Random Forest and SVM\n\nThe choice of SL algorithms as well as model parameters is arbitrary and is mostly based on:\n* the default values from packages' documentation\n* the arbitrary minimum of top basic SL models among other NLP kernels on Kaggle\n\nThe notebook is divided into several sections in order to evaluate final comparison of models.\n* **EDA:**<br/>\n    Couple of major visualizations to understand the distribution of number of articles per category and frequencies of words. With that we can have an idea whether to even the number of articles per category or to remove stopwords and other characters which do not carry much information about article's class.\n* **Preprocess data for modelling:**<br/>\n    Tokenization, lemmatization, stopwords removal. We're going to remove stopwords, convert texts into word-tokens and then convert those word-tokens to their base form. All of that is to improve model's performance and reduce training time.\n* **Unsupervised learning, NMF:**<br/>\n    NMF training based on the preprocessed text using several different parameters to choose the best one for later comparison with the SL. Mean accuracy scores computation via 5-fold cross validation.\n* **Supervised learning:**<br/>\n    Selection of the aforementioned SL algorithms and their training on the preprocessed data using different parameters as in the previous section. Mean accuracy scores computation via 5-fold cross validation.\n* **Comparison between NMF and SL:**<br/>\n    Final comparison is going to be presented as a table with models' accuracy scores and their runtime. This section is going to be comprised of 2 parts: results on the 100% of the dataset and on selected samples of it, specifically 50%, 20% and 10%.","metadata":{}},{"cell_type":"markdown","source":"### 3. Libraries and data <a class=\"anchor\" id=\"libraries_data\"></a>","metadata":{}},{"cell_type":"markdown","source":"#### 3.1 Libraries <a class=\"anchor\" id=\"libraries\"></a>","metadata":{}},{"cell_type":"code","source":"# basics\nimport numpy as np\nimport itertools\nimport random\nimport os\n\n# EDA\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Data preprocessing\nimport re\nimport spacy\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Unsupervised learning\nfrom sklearn.decomposition import NMF\n\n# Supervised learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\n\n# helper functions\nfrom sklearn.metrics import make_scorer, accuracy_score\nfrom sklearn.base import BaseEstimator, ClassifierMixin\nfrom sklearn.model_selection import GridSearchCV","metadata":{"execution":{"iopub.status.busy":"2023-10-08T16:54:33.499279Z","iopub.execute_input":"2023-10-08T16:54:33.500187Z","iopub.status.idle":"2023-10-08T16:54:51.353298Z","shell.execute_reply.started":"2023-10-08T16:54:33.500142Z","shell.execute_reply":"2023-10-08T16:54:51.352218Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"#### 3.2 Raw Data <a class=\"anchor\" id=\"raw_data\"></a>","metadata":{}},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2023-10-08T10:46:33.212068Z","iopub.execute_input":"2023-10-08T10:46:33.212419Z","iopub.status.idle":"2023-10-08T10:46:33.21922Z","shell.execute_reply.started":"2023-10-08T10:46:33.212377Z","shell.execute_reply":"2023-10-08T10:46:33.218325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/learn-ai-bbc/BBC News Train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/learn-ai-bbc/BBC News Test.csv\")\nsample_data = pd.read_csv(\"/kaggle/input/learn-ai-bbc/BBC News Sample Solution.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-10-08T10:46:39.132621Z","iopub.execute_input":"2023-10-08T10:46:39.132961Z","iopub.status.idle":"2023-10-08T10:46:39.204355Z","shell.execute_reply.started":"2023-10-08T10:46:39.132936Z","shell.execute_reply":"2023-10-08T10:46:39.203678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4. Exploratory Data Analysis <a class=\"anchor\" id=\"eda\"></a>","metadata":{}},{"cell_type":"markdown","source":"#### 4.1 Short Datasets Summary <a class=\"anchor\" id=\"short_summary\"></a>","metadata":{}},{"cell_type":"code","source":"def print_short_summary(name, data):\n    \"\"\"\n    Prints data head, shape and info.\n    Args:\n        name (str): name of dataset\n        data (dataframe): dataset in a pd.DataFrame format\n    \"\"\"\n    print(name)\n    print('\\n1. Data head:')\n    print(data.head())\n    print('\\n2. Data shape: {}'.format(data.shape))\n    print('\\n3. Data info:')\n    data.info()","metadata":{"execution":{"iopub.status.busy":"2023-10-08T10:46:44.839537Z","iopub.execute_input":"2023-10-08T10:46:44.839901Z","iopub.status.idle":"2023-10-08T10:46:44.844876Z","shell.execute_reply.started":"2023-10-08T10:46:44.839876Z","shell.execute_reply":"2023-10-08T10:46:44.844241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print_short_summary('Train dataset', train_data)","metadata":{"execution":{"iopub.status.busy":"2023-10-08T10:46:46.722613Z","iopub.execute_input":"2023-10-08T10:46:46.723539Z","iopub.status.idle":"2023-10-08T10:46:46.73469Z","shell.execute_reply.started":"2023-10-08T10:46:46.723511Z","shell.execute_reply":"2023-10-08T10:46:46.733932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print_short_summary('Test dataset',test_data)","metadata":{"execution":{"iopub.status.busy":"2023-10-08T10:46:47.962531Z","iopub.execute_input":"2023-10-08T10:46:47.962909Z","iopub.status.idle":"2023-10-08T10:46:47.973704Z","shell.execute_reply.started":"2023-10-08T10:46:47.962883Z","shell.execute_reply":"2023-10-08T10:46:47.972684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print_short_summary('Sample dataset',sample_data)","metadata":{"execution":{"iopub.status.busy":"2023-10-08T10:46:49.110351Z","iopub.execute_input":"2023-10-08T10:46:49.11128Z","iopub.status.idle":"2023-10-08T10:46:49.122032Z","shell.execute_reply.started":"2023-10-08T10:46:49.111236Z","shell.execute_reply":"2023-10-08T10:46:49.121446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 4.2 Number of Articles per Category <a class=\"anchor\" id=\"articles_per_category\"></a>","metadata":{}},{"cell_type":"markdown","source":"We can see that the number of articles per category doesn't vary much, which makes the training dataset somewhat balanced. Otherwise, we would have needed to either even the number of articles by reducing the sample size of categories or by choosing models which are kind of immune to the imbalanced dataset alongside with more relevant metrics such as F1-score or AUC.","metadata":{}},{"cell_type":"code","source":"# Plot histogram of number of articles per category\nplt.figure(figsize=(16, 9))\nsns.histplot(train_data, x = 'Category')\nplt.title('Category count disribution')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-08T10:46:52.563163Z","iopub.execute_input":"2023-10-08T10:46:52.563827Z","iopub.status.idle":"2023-10-08T10:46:52.855414Z","shell.execute_reply.started":"2023-10-08T10:46:52.563797Z","shell.execute_reply":"2023-10-08T10:46:52.854332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 4.3 Word Frequencies <a class=\"anchor\" id=\"word_frequencies\"></a>","metadata":{}},{"cell_type":"markdown","source":"Here we're going to examine texts closer on the matter of word importance. Prepositions, atricles, conjuctions can be considered irrelevant in determining category. From the text below it's also seen that apostrophes have been replaced be space leaving single letters untethered. These single words can be discarded in model training as well for the same reason of insignificance.","metadata":{}},{"cell_type":"code","source":"# Print category and text as an example\nprint('Category: {}\\n'.format(train_data['Category'][0]))\nprint('Text:\\n{}'.format(train_data['Text'][0]))","metadata":{"execution":{"iopub.status.busy":"2023-10-08T10:46:57.87052Z","iopub.execute_input":"2023-10-08T10:46:57.870846Z","iopub.status.idle":"2023-10-08T10:46:57.87567Z","shell.execute_reply.started":"2023-10-08T10:46:57.870819Z","shell.execute_reply":"2023-10-08T10:46:57.87493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot top 25 words by frequency\nw = train_data['Text'].str.split(expand=True).unstack().value_counts()\nl = w[:25]/np.sum(w)*100\nplt.figure(figsize=(16,9))\nplt.bar(l.index, l.values)\nplt.xlabel('Words')\nplt.ylabel('Percentage of total word count (%)')\nplt.title('Top 25 words by frequency')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-08T10:47:01.740468Z","iopub.execute_input":"2023-10-08T10:47:01.740814Z","iopub.status.idle":"2023-10-08T10:47:03.119112Z","shell.execute_reply.started":"2023-10-08T10:47:01.740788Z","shell.execute_reply":"2023-10-08T10:47:03.118449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 5. Data Preprocessing <a class=\"anchor\" id=\"data_preprocessing\"></a>","metadata":{}},{"cell_type":"markdown","source":"#### 5.1 Text Cleaning <a class=\"anchor\" id=\"text_cleaning\"></a>","metadata":{}},{"cell_type":"code","source":"# Load English dataset of lemmas and stopwords\nsp_process = spacy.load(\"en_core_web_sm\")\nstop_words = set(stopwords.words('english'))","metadata":{"execution":{"iopub.status.busy":"2023-10-08T10:47:07.562459Z","iopub.execute_input":"2023-10-08T10:47:07.56279Z","iopub.status.idle":"2023-10-08T10:47:08.209798Z","shell.execute_reply.started":"2023-10-08T10:47:07.562765Z","shell.execute_reply":"2023-10-08T10:47:08.208682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_clean_text(text):\n    \"\"\"\n    Returns lemmatized text without single letters and digits in lower case.\n    Args:\n        text (str): text of an article\n    Returns:\n        text (str): cleand text\n    \"\"\"\n    # Convert to lowercase\n    text = text.lower()\n    # Replace digits and single letters\n    pattern = r'\\b([a-zA-Z])\\b|\\d+|[.,!?()-\\:]'\n    text = re.sub(pattern, '', text)\n    # Tokenize\n    words = word_tokenize(text)\n    # Remove stopwords\n    words = [word for word in words if word not in stop_words]\n    # Lemmatize\n    text = sp_process(text)\n    words = [token.lemma_ for token in text]\n    # Join the words back into a string\n    text = ' '.join(words)\n    \n    return text\n","metadata":{"execution":{"iopub.status.busy":"2023-10-08T10:47:12.803852Z","iopub.execute_input":"2023-10-08T10:47:12.804496Z","iopub.status.idle":"2023-10-08T10:47:12.809068Z","shell.execute_reply.started":"2023-10-08T10:47:12.804467Z","shell.execute_reply":"2023-10-08T10:47:12.808432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Clean train and test datasets\nnpv = np.vectorize(get_clean_text)\ntrain_clean_data = npv(train_data['Text'])\ntest_clean_data = npv(test_data['Text'])","metadata":{"execution":{"iopub.status.busy":"2023-10-08T10:47:19.079828Z","iopub.execute_input":"2023-10-08T10:47:19.080477Z","iopub.status.idle":"2023-10-08T10:49:27.61108Z","shell.execute_reply.started":"2023-10-08T10:47:19.080448Z","shell.execute_reply":"2023-10-08T10:49:27.610267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print an example of the cleaned text\ntrain_clean_data[0]","metadata":{"execution":{"iopub.status.busy":"2023-10-08T10:50:06.122607Z","iopub.execute_input":"2023-10-08T10:50:06.123318Z","iopub.status.idle":"2023-10-08T10:50:06.128933Z","shell.execute_reply.started":"2023-10-08T10:50:06.123289Z","shell.execute_reply":"2023-10-08T10:50:06.128023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 5.2 TF-IDF Vectorization <a class=\"anchor\" id=\"tfidf_vectorization\"></a>","metadata":{}},{"cell_type":"markdown","source":"TF-IDF, or Term Frequency-Inverse Document Frequency, is a numerical statistic that reflects how important a word is to an article in a collection of such. This reflection is later used as the word weight in modelling. With these weights TF-IDF supposedly enhances the model's ability to find unique and relevant words within each article, eventually improving the accuracy.","metadata":{}},{"cell_type":"code","source":"# Convert text to TF-IDF features\nvectorizer = TfidfVectorizer(sublinear_tf = True\n                             , min_df = 5\n                             , stop_words = 'english'\n                             , norm = 'l2'\n                             , encoding = 'latin-1'\n                             , ngram_range = (1,2)\n                             )\ntfidf_vect = vectorizer.fit(train_clean_data)\nX_train = tfidf_vect.transform(train_clean_data)\nX_test = tfidf_vect.transform(test_clean_data)\n\ny_train = train_data['Category']\ny_test = sample_data['Category']","metadata":{"execution":{"iopub.status.busy":"2023-10-08T10:50:13.457073Z","iopub.execute_input":"2023-10-08T10:50:13.457455Z","iopub.status.idle":"2023-10-08T10:50:15.224889Z","shell.execute_reply.started":"2023-10-08T10:50:13.457429Z","shell.execute_reply":"2023-10-08T10:50:15.223843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 6. Data Modelling <a class=\"anchor\" id=\"data_modelling\"></a>","metadata":{}},{"cell_type":"markdown","source":"Since we're extensively using GridSearchCV in our modelling, there is no need to additionaly split our train dataset into training and testing samples. The reason for that is a built-in cross validation function which already takes responsibility in splitting training set into (k-1) parts to train on and the remaining to test on. We're going to use 5-fold cross-validation.","metadata":{}},{"cell_type":"code","source":"def get_results_table(results):\n    \"\"\"\n    Returns table of models' results sorted by accuracy and runtime\n    Args:\n        results (dataframe): table of models' results\n    Returns:\n        df (dataframe): pd.DataFrame with selected columns sorted by accuracy and runtime\n    \"\"\"\n    columns = ['model','params','mean_fit_time','mean_score_time','mean_train_score', 'mean_test_score']\n    df = results.copy()[columns]\n    df['mean_runtime'] = df['mean_fit_time'] + df['mean_score_time']\n    df = df[['model','params','mean_runtime','mean_train_score','mean_test_score']]\n    df = df.sort_values(by=['mean_test_score','mean_runtime'], ascending=[False,True])\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2023-10-08T10:52:09.852594Z","iopub.execute_input":"2023-10-08T10:52:09.852954Z","iopub.status.idle":"2023-10-08T10:52:09.859369Z","shell.execute_reply.started":"2023-10-08T10:52:09.85293Z","shell.execute_reply":"2023-10-08T10:52:09.858441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### 6.1 Unsupervised Learning (NMF) <a class=\"anchor\" id=\"ul_nmf\"></a>","metadata":{}},{"cell_type":"markdown","source":"In this section we're going to train unsupervised model with different parameters. In our case it is going to be NMF.<br/>Since we do not want end up neither in overfitting nor in underfitting, it's better to use our tokenized features only from training dataset and evaluate model performance on 100% of such.<br/>However, additional experiments in regard to using only 50%, 20% and 10% of the training dataset will be conducted in the Section 7 as well. The reason for this is to reveal which model requires a smaller amount of data to achieve similar results or in other words more data-efficient.","metadata":{}},{"cell_type":"code","source":"def get_max_accuracy(y_true, y_pred):\n    \"\"\"\n    Returns max accuracy among category permutations\n    Args:\n        y_true (ndarray): true labels of a dataset\n        y_pred (ndarray): predicted lables from a model\n    Returns:\n        mx (float): maximum accuracy score among all category permutations\n    \"\"\"\n    y_pred = np.argmax(y_pred, axis = 1)\n    l = np.unique(y_true)\n    t = y_true.values\n    mx = 0\n    for p in itertools.permutations(range(len(l))):\n        c = np.array([l[p.index(x)] for x in y_pred])\n        v = np.mean(c == t)\n        mx = max(mx,v)\n            \n    return mx","metadata":{"execution":{"iopub.status.busy":"2023-10-08T10:52:14.126506Z","iopub.execute_input":"2023-10-08T10:52:14.12684Z","iopub.status.idle":"2023-10-08T10:52:14.132927Z","shell.execute_reply.started":"2023-10-08T10:52:14.126799Z","shell.execute_reply":"2023-10-08T10:52:14.13208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class NMF_custom(BaseEstimator, ClassifierMixin):\n    \"\"\"\n    Custom NMF class to use in conjunction with GridSearchCV\n    , so that predict() function can be used in the cross validation\n    Inherited classes:\n        BaseEstimator, ClassifierMixin: necessary for the GridSearchCV\n    \"\"\"\n    def __init__(self, n_components = 5, init = None, l1_ratio = 0, max_iter = 200):\n        \"\"\"\n        Set self variables to the arguments for the fit() function\n        Args:\n            smaller set of the same arguments as in the docs of NMF\n        \"\"\"\n        self.n_components = n_components\n        self.init = init\n        self.l1_ratio = l1_ratio\n        self.max_iter = max_iter\n\n    def fit(self, X, y=None):\n        \"\"\"\n        Fit NMF to the X data using self variables\n        Args:\n            X (ndarray): data to fit\n        Returns:\n            self\n        \"\"\"\n        self.nmf = NMF(n_components = self.n_components\n                       , init = self.init\n                       , l1_ratio = self.l1_ratio\n                       , max_iter = self.max_iter)\n        self.nmf.fit(X)\n        return self\n\n    def predict(self, X):\n        \"\"\"\n        Transform X using fitted model to use as a prediction\n        Args:\n            X (ndarray): data to predict from\n        Returns:\n            self.nmf.transform (ndarray): ndarray of predicted categories\n        \"\"\"\n        return self.nmf.transform(X)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-08T10:52:16.935031Z","iopub.execute_input":"2023-10-08T10:52:16.935349Z","iopub.status.idle":"2023-10-08T10:52:16.942933Z","shell.execute_reply.started":"2023-10-08T10:52:16.935325Z","shell.execute_reply":"2023-10-08T10:52:16.941891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_table_grid_nmf(X_train, y_train):\n    \"\"\"\n    Returns tuple (table, best_estimator)\n    Args:\n        X_train (ndarray): data to train on\n        y_train (ndarray): training labels for GridSearchCV evaluation\n    Returns:\n        (table, grid.best_estimator_)\n    \"\"\"\n    # Number of unique categories\n    n_unq_cat = len(np.unique(train_data['Category'].values))\n    # Parameter grid to use in GridSearchCV\n    param_grid = {\n        'n_components': [n_unq_cat]\n        ,'init': ['random', 'nndsvda']\n        ,'l1_ratio': [0.0, 0.5, 1.0]\n        ,'max_iter': [200, 400, 600]\n    }\n    # Create GridSearchCV object with custom scoring function\n    grid = GridSearchCV(estimator = NMF_custom()\n                        , param_grid = param_grid\n                        , scoring = make_scorer(get_max_accuracy)\n                        , return_train_score = True\n                        , cv = 5)\n    # Fit X_train\n    grid = grid.fit(X_train, y_train)\n    # Add new key 'model' as a name of the trained model for later use in a table\n    n = len(grid.cv_results_['params'])\n    grid.cv_results_['model'] = ['NMF']*n\n    # Convert dictionary of ndarray to dataframe\n    table = pd.DataFrame(grid.cv_results_)\n    # Get cleaned table and sorted by accuracy and runtime\n    table = get_results_table(table)\n    \n    return (table, grid.best_estimator_)","metadata":{"execution":{"iopub.status.busy":"2023-10-08T10:52:21.142859Z","iopub.execute_input":"2023-10-08T10:52:21.143191Z","iopub.status.idle":"2023-10-08T10:52:21.15036Z","shell.execute_reply.started":"2023-10-08T10:52:21.143167Z","shell.execute_reply":"2023-10-08T10:52:21.14931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results_nmf, best_nmf = get_table_grid_nmf(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-10-08T10:52:24.742413Z","iopub.execute_input":"2023-10-08T10:52:24.742737Z","iopub.status.idle":"2023-10-08T10:52:56.979807Z","shell.execute_reply.started":"2023-10-08T10:52:24.742714Z","shell.execute_reply":"2023-10-08T10:52:56.978444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Top 10 NMF models\nresults_nmf[:10]","metadata":{"execution":{"iopub.status.busy":"2023-10-08T10:54:53.363224Z","iopub.execute_input":"2023-10-08T10:54:53.363627Z","iopub.status.idle":"2023-10-08T10:54:53.37777Z","shell.execute_reply.started":"2023-10-08T10:54:53.363596Z","shell.execute_reply":"2023-10-08T10:54:53.376849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### 6.2 Supervised Learning (SL) <a class=\"anchor\" id=\"sl\"></a>","metadata":{}},{"cell_type":"code","source":"# Create a list of dictionaries to use in the GridSearchCV within the loop\nmodel_params = [\n    {\n        'model': LogisticRegression()\n        ,'name': 'LogReg'\n        ,'param_grid':\n        {\n            'penalty': ['l1', 'l2']\n            ,'C': [0.001,  0.1]\n            ,'solver': ['saga']\n        }\n    }\n    ,{\n        'model': RandomForestClassifier()\n        ,'name': 'Random Forest'\n        ,'param_grid':\n        {\n            'n_estimators': [50, 100]\n            ,'max_depth': [None, 10]\n        }\n    }\n    ,{\n        'model': SVC()\n        ,'name': 'SVM'\n        ,'param_grid':\n        {\n            'C': [0.1, 1, 10]\n            ,'kernel': ['rbf']\n            ,'gamma': [0.1, 1, 10]\n        }\n    }\n]","metadata":{"execution":{"iopub.status.busy":"2023-10-08T10:55:01.833165Z","iopub.execute_input":"2023-10-08T10:55:01.833535Z","iopub.status.idle":"2023-10-08T10:55:01.8396Z","shell.execute_reply.started":"2023-10-08T10:55:01.833509Z","shell.execute_reply":"2023-10-08T10:55:01.838975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_table_grid_sl(model_params, X_train, y_train):\n    \"\"\"\n    Returns a table of all results from selected models and their parameters\n    Args:\n        models_params (list): list of dictionaries of models to train\n        X_train (ndarray): data to train\n        y_train (ndarray): labels to compute accuracy score\n    Returns:\n        table (list): list of dictionaries with results from training via GridSeachCV\n    \"\"\"\n    n = len(model_params)\n    table = []\n    max_score = 0\n    best_sl = None\n    # Loop through all the models with specified parameters\n    for i in range(n):\n        # Create GridSeachCV object with specified parameters\n        grid = GridSearchCV(model_params[i]['model']\n                            , model_params[i]['param_grid']\n                            , return_train_score = True\n                            , cv = 5)\n        # Fit object to training data\n        grid = grid.fit(X_train, y_train)\n        # Add new key 'model' for later depiction in a table comparison\n        n = len(grid.cv_results_['params'])\n        grid.cv_results_['model'] = [model_params[i]['name']]*n\n        # Append GridSearchCV results to the table list\n        table.append(grid.cv_results_)\n        if grid.best_score_ > max_score:\n            max_score = grid.best_score_\n            best_sl = grid.best_estimator_\n\n    return (table, best_sl)","metadata":{"execution":{"iopub.status.busy":"2023-10-08T10:55:05.47222Z","iopub.execute_input":"2023-10-08T10:55:05.472583Z","iopub.status.idle":"2023-10-08T10:55:05.479486Z","shell.execute_reply.started":"2023-10-08T10:55:05.472559Z","shell.execute_reply":"2023-10-08T10:55:05.478584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get SL models' results in a list of dictionaries\nresults_sl, best_sl = get_table_grid_sl(model_params, X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-10-08T10:55:14.168172Z","iopub.execute_input":"2023-10-08T10:55:14.168534Z","iopub.status.idle":"2023-10-08T10:59:04.888262Z","shell.execute_reply.started":"2023-10-08T10:55:14.168498Z","shell.execute_reply":"2023-10-08T10:59:04.887453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_readable_table_sl(results_sl):\n    \"\"\"\n    Returns readable dataframe with GridSearchCV results on every row\n    Args:\n        results_sl (list): list of GridSearchCV dictionaries with results\n    Returns:\n        results_sl (dataframe): cleaned dataframe with results on every row\n    \"\"\"\n    df = pd.DataFrame(results_sl)\n    df = df.explode(['model'\n                     ,'params'\n                     ,'mean_fit_time'\n                     ,'mean_score_time'\n                     ,'mean_train_score'\n                     ,'mean_test_score']\n                    , ignore_index=True)\n    # Get cleaned dataframe that is sorted by accuracy and runtime\n    results_sl = get_results_table(df)\n    \n    return results_sl","metadata":{"execution":{"iopub.status.busy":"2023-10-08T11:00:59.713605Z","iopub.execute_input":"2023-10-08T11:00:59.713959Z","iopub.status.idle":"2023-10-08T11:00:59.71953Z","shell.execute_reply.started":"2023-10-08T11:00:59.713934Z","shell.execute_reply":"2023-10-08T11:00:59.718286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert results_sl list to readable Dataframe\nresults_sl = get_readable_table_sl(results_sl)","metadata":{"execution":{"iopub.status.busy":"2023-10-08T11:01:05.330653Z","iopub.execute_input":"2023-10-08T11:01:05.331013Z","iopub.status.idle":"2023-10-08T11:01:05.346256Z","shell.execute_reply.started":"2023-10-08T11:01:05.330989Z","shell.execute_reply":"2023-10-08T11:01:05.345559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Top 10 Supervised models\nresults_sl[:10]","metadata":{"execution":{"iopub.status.busy":"2023-10-08T11:01:08.148415Z","iopub.execute_input":"2023-10-08T11:01:08.148926Z","iopub.status.idle":"2023-10-08T11:01:08.162315Z","shell.execute_reply.started":"2023-10-08T11:01:08.148899Z","shell.execute_reply":"2023-10-08T11:01:08.161482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 7. Model Results Comparison between NMF and SL <a class=\"anchor\" id=\"comparison\"></a>","metadata":{}},{"cell_type":"markdown","source":"This section consists of 2 parts: model comparison using full dataset and using only fraction of it, concretely 50%, 20% and 10%.<br/>\nIn the first part we're going to see the main results of this study, mainly to help answer this question: does NMF perform better or worse than selected SL models.<br/>\nSecond part is going to be about comparing SL models vs NMF models on the different portions of the train data. The main goal here is to reveal which model is more data efficient than others.","metadata":{}},{"cell_type":"markdown","source":"#### 7.1 Full Train Dataset <a class=\"anchor\" id=\"full_train_dataset\"></a>","metadata":{}},{"cell_type":"code","source":"# Concatenate two tables from NMF and SL results into one and sort in the same manner\nresults_total = pd.concat([results_nmf, results_sl], axis=0, ignore_index=True)\nresults_total = results_total.sort_values(by=['mean_test_score','mean_runtime']\n                          , ascending=[False,True])","metadata":{"execution":{"iopub.status.busy":"2023-10-08T11:01:15.562575Z","iopub.execute_input":"2023-10-08T11:01:15.562888Z","iopub.status.idle":"2023-10-08T11:01:15.570546Z","shell.execute_reply.started":"2023-10-08T11:01:15.562867Z","shell.execute_reply":"2023-10-08T11:01:15.569652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Top 10 Model Ratings\nresults_total[:10]","metadata":{"execution":{"iopub.status.busy":"2023-10-08T11:01:17.822358Z","iopub.execute_input":"2023-10-08T11:01:17.822958Z","iopub.status.idle":"2023-10-08T11:01:17.834649Z","shell.execute_reply.started":"2023-10-08T11:01:17.82293Z","shell.execute_reply":"2023-10-08T11:01:17.833821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 7.2 Samples of the Train Dataset <a class=\"anchor\" id=\"samples_train_dataset\"></a>","metadata":{}},{"cell_type":"markdown","source":"Given the set of arbitrary samples of the train data, 50%, 20% and 10%, to test on, we can observe rather interesting results. Every model except LogReg scored surprisingly good, having loss in the accuracy within 2%, while traning just on the half of the provided data. This is an important observation, since it provides opportunity to increase computational speed with only a small drop in the accuracy score.\n\nThe overfitting problem can also be observed here, as the mean train score is generally higher than mean test score across selected models. But what stands out the most are the NMF results. While SL models kept increasing overfitting with the sample size reduction, NMF test scores not only stayed at the same level as the train scores, but once were even higher. That might be due to the fact that NMF doesn't account labels during training session. Which in this particular case gave an advantage over SL algorithms.","metadata":{}},{"cell_type":"code","source":"def get_table_samples(samples):\n    \"\"\"\n    Returns final table of SL and NMF training results by fraction of the data\n    Args:\n        parts (list): list of fractions to select from dataset\n    Returns:\n        table (dataframe): final training results table\n    \"\"\"\n    n = X_train.shape[0]\n    table = pd.DataFrame()\n    for i in range(len(samples)):\n        n = int(samples[i] * n)\n        # Create list of indexes\n        indexes = list(range(n))\n        # Shuffle the list of indexes randomly\n        random.shuffle(indexes)\n        # Select fraction of the shuffled indexes\n        indexes = indexes[:n]\n        # Get tables of SL and NMF results\n        results_sl, best_sl = get_table_grid_sl(model_params, X_train[indexes], y_train[indexes])\n        results_nmf, best_nmf = get_table_grid_nmf(X_train[indexes], y_train[indexes])\n        # Convert results_sl to readable dataframe\n        results_sl = get_readable_table_sl(results_sl)\n        # Create temporary table of results_sl and results_nmf\n        temp_table = pd.concat([results_nmf, results_sl], axis=0, ignore_index=True)\n        # Set column sample for clarification\n        temp_table['sample'] = samples[i]\n        # Concatenate with final table\n        table = pd.concat([temp_table, table], axis = 0, ignore_index = True)\n    \n    return table","metadata":{"execution":{"iopub.status.busy":"2023-10-08T11:01:42.461972Z","iopub.execute_input":"2023-10-08T11:01:42.462328Z","iopub.status.idle":"2023-10-08T11:01:42.469672Z","shell.execute_reply.started":"2023-10-08T11:01:42.462302Z","shell.execute_reply":"2023-10-08T11:01:42.468554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the table of training results in regard to selected sample of the dataset\nsamples = [0.5, 0.2, 0.1]\n\nresults_samples = get_table_samples(samples)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model Ratings based on the samples\nresults_samples.fillna(0, inplace = True)\ntemp_table = results_total.copy()\ntemp_table['sample'] = 1.0\ntemp_table['mean_train_score'] = temp_table['mean_train_score'].astype(float)\ntemp_table['mean_test_score'] = temp_table['mean_test_score'].astype(float)\nresult = pd.concat([temp_table, results_samples], axis=0, ignore_index=True)\nresult = result.groupby(['model', 'sample']).apply(lambda x: x.loc[x['mean_test_score'].idxmax()])\nresult = result.drop('sample', axis = 1)\nresult","metadata":{"execution":{"iopub.status.busy":"2023-10-08T11:07:06.877228Z","iopub.execute_input":"2023-10-08T11:07:06.877983Z","iopub.status.idle":"2023-10-08T11:07:06.909227Z","shell.execute_reply.started":"2023-10-08T11:07:06.87795Z","shell.execute_reply":"2023-10-08T11:07:06.908498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 8. Submission Results <a class=\"anchor\" id=\"submission_results\"></a>","metadata":{}},{"cell_type":"code","source":"# Make short table of top SL and NMF models performances\n\ny_pred = best_sl.predict(X_test)\nresults = test_data.copy()\nresults['Category'] = y_pred\nresults.drop('Text', axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2023-10-08T11:08:03.280531Z","iopub.execute_input":"2023-10-08T11:08:03.280854Z","iopub.status.idle":"2023-10-08T11:08:04.268166Z","shell.execute_reply.started":"2023-10-08T11:08:03.280832Z","shell.execute_reply":"2023-10-08T11:08:04.267411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print results table\nresults","metadata":{"execution":{"iopub.status.busy":"2023-10-08T11:08:11.820012Z","iopub.execute_input":"2023-10-08T11:08:11.820329Z","iopub.status.idle":"2023-10-08T11:08:11.830153Z","shell.execute_reply.started":"2023-10-08T11:08:11.820307Z","shell.execute_reply":"2023-10-08T11:08:11.82936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make submission\nresults.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-07T21:04:33.120307Z","iopub.execute_input":"2023-10-07T21:04:33.120725Z","iopub.status.idle":"2023-10-07T21:04:33.131074Z","shell.execute_reply.started":"2023-10-07T21:04:33.12069Z","shell.execute_reply":"2023-10-07T21:04:33.130157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Submission's public score: 0.98231","metadata":{}},{"cell_type":"markdown","source":"#### 9. Conclusion <a class=\"anchor\" id=\"conclusion\"></a>","metadata":{}},{"cell_type":"markdown","source":"The superior performance of supervised learning, SVM and RF concretely, suggests that in our situation where labeled data is available and the task demands high predictive accuracy, SVM and RF prove to be more effective.\n\nOne of the possible explanation for such success is the obvious one: these models leverage the labeled data to learn patterns and relationships within the data, enabling them to make more accurate predictions.\n\nHowever, NMF, being in a disadvantage, still holds significant value. As can be seen in the table though its accuracy is slightly worse, it took much less time to run calculations in comparison to the leader - SVM. That makes NMF very attractive in the case of unlabeled data, as it provides good performance, and, what's more interesting, it can be considered for the labeled data as well if we were to trade a slight drop in the accuracy for higher computational speed.\n\nAdditionally, it's crucial to point out, that most of the models scored surprisingly good, having slight loss in the accuracy score, while traning just on the half of the provided data. Especially surprising results gave NMF, when on every sample size it provided test scores on par with the train scores. This observation tells us that not only algorithm efficiency or feature engineering, but the reduction of the sample size itself may lead to a good speed-accuracy trade-off.","metadata":{}},{"cell_type":"markdown","source":"#### 10. References <a class=\"anchor\" id=\"references\"></a>","metadata":{}},{"cell_type":"markdown","source":"* Problem-solving with ML: automatic document classification<br/>\nhttps://cloud.google.com/blog/products/ai-machine-learning/problem-solving-with-ml-automatic-document-classification\n* Scikit-learn API Reference<br/>\nhttps://scikit-learn.org/stable/modules/classes.html\n* Basic EDA,Cleaning and GloVe<br/>\nhttps://www.kaggle.com/code/shahules/basic-eda-cleaning-and-glove/notebook\n* Approaching (Almost) Any NLP Problem on Kaggle<br/>\nhttps://www.kaggle.com/code/abhishek/approaching-almost-any-nlp-problem-on-kaggle\n* Spooky NLP and Topic Modelling tutorial<br/>\nhttps://www.kaggle.com/code/arthurtok/spooky-nlp-and-topic-modelling-tutorial/notebook\n* [Fake News] Easy NLP Text Classification!<br/>\nhttps://www.kaggle.com/code/ohseokkim/fake-news-easy-nlp-text-classification","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}